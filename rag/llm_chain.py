"""
LLM éˆè™•ç†
è² è²¬å•ç­”ç”Ÿæˆå’Œå›è¦†éˆçš„å»ºç«‹
"""
from typing import Iterator, Optional
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama
from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import BaseRetriever
from langchain.prompts import ChatPromptTemplate

from config import LLMConfig, CharacterConfig

def format_docs(docs):
    """å°‡æª¢ç´¢åˆ°çš„æ–‡ä»¶æ ¼å¼åŒ–ç‚ºå­—ä¸²"""
    return "\n\n".join(doc.page_content for doc in docs)

class LLMChain:
    """LLM å•ç­”éˆ"""
    
    def __init__(self, retriever: BaseRetriever):
        self.retriever = retriever
        self.llm = self._setup_llm()
        self.prompt = self._setup_prompt()
        self.rag_chain = self._build_rag_chain()
    
    def _setup_llm(self):
        """è¨­ç½® LLM æ¨¡å‹"""
        if LLMConfig.ACTIVE_LLM == "groq":
            print("ä½¿ç”¨ Groq æ¨¡å‹")
            return ChatOpenAI(
                model=LLMConfig.GROQ_MODEL,
                openai_api_base=LLMConfig.GROQ_BASE_URL,
                openai_api_key=LLMConfig.GROQ_API_KEY
            )
        elif LLMConfig.ACTIVE_LLM == "ollama":
            print("ä½¿ç”¨ Ollama æ¨¡å‹")
            return ChatOllama(
                model=LLMConfig.OLLAMA_MODEL,
                base_url=LLMConfig.OLLAMA_BASE_URL
            )
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ LLM é¡å‹: {LLMConfig.ACTIVE_LLM}")
    
    def _setup_prompt(self):
        """è¨­ç½® Prompt æ¨¡æ¿"""
        try:
            # å¾ hub è¼‰å…¥é è¨­çš„ RAG prompt
            prompt = hub.pull("rlm/rag-prompt").partial(
                system_message=CharacterConfig.SYSTEM_MESSAGE
            )
            return prompt
        except Exception as e:
            print(f"ç„¡æ³•å¾ hub è¼‰å…¥ promptï¼Œä½¿ç”¨é è¨­æ¨¡æ¿: {e}")
            # å‚™ç”¨çš„ prompt æ¨¡æ¿
            return ChatPromptTemplate.from_messages([
                ("system", CharacterConfig.SYSTEM_MESSAGE),
                ("human", """åŸºæ–¼ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”å•é¡Œï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

å•é¡Œï¼š{question}

å›ç­”ï¼š""")
            ])
    
    def _build_rag_chain(self):
        """å»ºç«‹ RAG éˆ"""
        return (
            {"context": self.retriever | format_docs, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
    
    def ask(self, question: str) -> str:
        """
        åŒæ­¥å•ç­”
        
        Args:
            question: å•é¡Œæ–‡æœ¬
            
        Returns:
            str: å®Œæ•´å›ç­”
        """
        try:
            response = self.rag_chain.invoke(question)
            return response
        except Exception as e:
            return f"ç™¼ç”ŸéŒ¯èª¤: {e}"
    
    def ask_stream(self, question: str) -> Iterator[str]:
        """
        ä¸²æµå•ç­”
        
        Args:
            question: å•é¡Œæ–‡æœ¬
            
        Yields:
            str: å›ç­”ç‰‡æ®µ
        """
        try:
            for chunk in self.rag_chain.stream(question):
                yield chunk
        except Exception as e:
            yield f"ç™¼ç”ŸéŒ¯èª¤: {e}"
    
    def ask_with_context_display(self, question: str) -> tuple[str, list]:
        """
        å•ç­”ä¸¦è¿”å›ä½¿ç”¨çš„ä¸Šä¸‹æ–‡
        
        Args:
            question: å•é¡Œæ–‡æœ¬
            
        Returns:
            tuple: (å›ç­”, æª¢ç´¢åˆ°çš„æ–‡æª”åˆ—è¡¨)
        """
        try:
            # å…ˆç²å–æª¢ç´¢åˆ°çš„æ–‡æª”
            retrieved_docs = self.retriever.invoke(question)
            
            # ç”Ÿæˆå›ç­”
            response = self.rag_chain.invoke(question)
            
            return response, retrieved_docs
        except Exception as e:
            return f"ç™¼ç”ŸéŒ¯èª¤: {e}", []

class WednesdayChat:
    """Wednesday Addams èŠå¤©åŠ©æ‰‹ï¼ˆæ”¯æŒ TTSï¼‰"""
    
    def __init__(self, llm_chain: LLMChain, enable_tts: bool = True):
        self.llm_chain = llm_chain
        self.enable_tts = enable_tts
        
        # åˆå§‹åŒ– TTSï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if self.enable_tts:
            try:
                from tts.gpt_sovits_tts import GPTSoVITSTTS
                self.tts = GPTSoVITSTTS()
                print("âœ… TTS åŠŸèƒ½å·²å•Ÿç”¨")
            except Exception as e:
                print(f"âš ï¸  TTS åˆå§‹åŒ–å¤±æ•—ï¼Œåƒ…ä½¿ç”¨æ–‡æœ¬æ¨¡å¼: {e}")
                self.tts = None
                self.enable_tts = False
        else:
            self.tts = None
    
    def chat(self, user_input: str, with_audio: bool = None) -> tuple[str, Optional[str]]:
        """
        èˆ‡ Wednesday èŠå¤©
        
        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥
            with_audio: æ˜¯å¦ç”ŸæˆéŸ³é »ï¼ˆNone å‰‡ä½¿ç”¨åˆå§‹åŒ–è¨­å®šï¼‰
            
        Returns:
            tuple: (æ–‡æœ¬å›è¦†, éŸ³é »æª”æ¡ˆè·¯å¾‘æˆ–None)
        """
        # æ§‹å»ºå®Œæ•´çš„å•é¡Œ
        full_question = (
            "è«‹ä»¥ Wednesday Addams çš„å£å»ï¼Œç”¨ç¬¬ä¸€äººç¨±ç›´æ¥å’Œæˆ‘èªªè©±ä¸”ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œ"
            f"å›ç­”æˆ‘ä¸‹é¢çš„å•é¡Œï¼š{user_input}"
        )
        
        # ç²å–æ–‡æœ¬å›è¦†
        text_response = self.llm_chain.ask(full_question)
        
        # ç”ŸæˆéŸ³é »ï¼ˆå¦‚æœéœ€è¦ï¼‰
        audio_path = None
        if (with_audio is True) or (with_audio is None and self.enable_tts and self.tts):
            try:
                print("ğŸ”Š æ­£åœ¨ç”ŸæˆèªéŸ³...")
                audio_path = self.tts.synthesize_from_response(text_response)
                if audio_path:
                    print(f"âœ… èªéŸ³ç”Ÿæˆå®Œæˆ: {audio_path}")
                else:
                    print("âš ï¸  èªéŸ³ç”Ÿæˆå¤±æ•—")
            except Exception as e:
                print(f"âŒ èªéŸ³ç”ŸæˆéŒ¯èª¤: {e}")
        
        return text_response, audio_path
    
    def chat_stream(self, user_input: str) -> Iterator[str]:
        """
        èˆ‡ Wednesday ä¸²æµèŠå¤©ï¼ˆåƒ…æ–‡æœ¬ï¼‰
        
        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥
            
        Yields:
            str: Wednesday å›è¦†çš„ç‰‡æ®µ
        """
        # æ§‹å»ºå®Œæ•´çš„å•é¡Œ
        full_question = (
            "è«‹ä»¥ Wednesday Addams çš„å£å»ï¼Œç”¨ç¬¬ä¸€äººç¨±ç›´æ¥å’Œæˆ‘èªªè©±ä¸”ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œ"
            f"å›ç­”æˆ‘ä¸‹é¢çš„å•é¡Œï¼š{user_input}"
        )
        
        for chunk in self.llm_chain.ask_stream(full_question):
            yield chunk
    
    def chat_stream_with_tts(self, user_input: str) -> tuple[Iterator[str], str]:
        """
        ä¸²æµèŠå¤©ä¸¦åœ¨çµæŸå¾Œç”ŸæˆéŸ³é »
        
        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥
            
        Returns:
            tuple: (æ–‡æœ¬ä¸²æµè¿­ä»£å™¨, æœ€çµ‚å®Œæ•´å›è¦†)
        """
        # æ”¶é›†å®Œæ•´å›è¦†
        full_response = ""
        
        def response_generator():
            nonlocal full_response
            for chunk in self.chat_stream(user_input):
                full_response += chunk
                yield chunk
        
        # è¿”å›ç”Ÿæˆå™¨å’Œè¨ˆåŠƒåœ¨å¾ŒçºŒåŸ·è¡Œçš„ TTS
        return response_generator(), full_response
    
    def generate_audio_for_text(self, text: str) -> Optional[str]:
        """
        ç‚ºæŒ‡å®šæ–‡æœ¬ç”ŸæˆéŸ³é »
        
        Args:
            text: è¦è½‰æ›çš„æ–‡æœ¬
            
        Returns:
            str: éŸ³é »æª”æ¡ˆè·¯å¾‘æˆ–None
        """
        if not self.tts:
            print("âŒ TTS æœªå•Ÿç”¨")
            return None
        
        try:
            return self.tts.synthesize_from_response(text)
        except Exception as e:
            print(f"âŒ éŸ³é »ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    def play_audio(self, audio_path: str):
        """
        æ’­æ”¾éŸ³é »æª”æ¡ˆ
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
        """
        if self.tts:
            self.tts.play_audio(audio_path)
        else:
            print("âŒ TTS æœªå•Ÿç”¨ï¼Œç„¡æ³•æ’­æ”¾éŸ³é »")
    
    def toggle_tts(self, enabled: bool):
        """
        åˆ‡æ› TTS åŠŸèƒ½
        
        Args:
            enabled: æ˜¯å¦å•Ÿç”¨ TTS
        """
        if enabled and not self.tts:
            try:
                from tts.gpt_sovits_tts import GPTSoVITSTTS
                self.tts = GPTSoVITSTTS()
                self.enable_tts = True
                print("âœ… TTS åŠŸèƒ½å·²å•Ÿç”¨")
            except Exception as e:
                print(f"âŒ TTS å•Ÿç”¨å¤±æ•—: {e}")
        elif not enabled:
            self.enable_tts = False
            print("âš ï¸  TTS åŠŸèƒ½å·²åœç”¨")

if __name__ == "__main__":
    # æ¸¬è©¦ LLM éˆ
    from rag.loader import DocumentLoader
    from rag.retriever import VectorRetriever
    
    # è¼‰å…¥æ–‡æª”ä¸¦å»ºç«‹æª¢ç´¢å™¨
    loader = DocumentLoader()
    documents = loader.load_and_split()
    
    if documents:
        retriever_instance = VectorRetriever()
        retriever = retriever_instance.get_retriever(documents)
        
        # å»ºç«‹ LLM éˆ
        llm_chain = LLMChain(retriever)
        
        # å»ºç«‹ Wednesday èŠå¤©åŠ©æ‰‹
        wednesday = WednesdayChat(llm_chain)
        
        # æ¸¬è©¦èŠå¤©
        test_question = "ä½ æœ€å–œæ­¡ä»€éº¼é¡è‰²ï¼Ÿ"
        print(f"å•é¡Œ: {test_question}")
        print("Wednesday çš„å›ç­”:")
        
        # ä¸²æµå›ç­”
        for chunk in wednesday.chat_stream(test_question):
            print(chunk, end="", flush=True)
        print()
    else:
        print("æ²’æœ‰æ‰¾åˆ°æ–‡æª”ï¼Œè«‹ç¢ºä¿ scripts è³‡æ–™å¤¾ä¸­æœ‰ PDF æª”æ¡ˆ")
